{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Mastodon social media posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, Consumer, KafkaError # to produce and consume data from Apache Kafka topics\n",
    "import boto3 # to programmatically create, configure, and manage AWS resources\n",
    "import json # to work with social media messages that are represented as JSON objects\n",
    "import re # for helper functionality to clean HTML tags from social media messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a method to invoke the endpoints that we have deployed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model_endpoint(endpoint_name, text):\n",
    "    input_data = json.dumps({\"inputs\": text})\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    query_response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=input_data, Accept='application/json')\n",
    "    return json.loads(query_response['Body'].read())\n",
    "\n",
    "# usage:\n",
    "# print(invoke_model_endpoint('roberta-base-sentiment','cat'));\n",
    "# print(invoke_model_endpoint('twitter-roberta-base-offensive-endpoint','cat'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Kafka workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Apache Kafka connection properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load Apache Kafka certificates into certificates folder\n",
    "apache_kafka_ssl_config = {\n",
    "    'ssl.ca.location': 'certificates/ca.pem', \n",
    "    'ssl.certificate.location': 'certificates/service.cert',\n",
    "    'ssl.key.location': 'certificates/service.key',\n",
    "    'security.protocol': 'ssl',\n",
    "}\n",
    "\n",
    "apache_kafka_uri = ''  # TODO: Set URI for Apache Kafka\n",
    "\n",
    "apache_kafka_input_topic_name = 'mastodon_posts'\n",
    "apache_kafka_enriched_output_topic_name = 'mastodon_posts_enriched'\n",
    "apache_kafka_processing_errors_topic_name = 'mastodon_posts_processing_errors'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Apache Kafka Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer({'bootstrap.servers': apache_kafka_uri, 'group.id': 'mygroup10', 'auto.offset.reset': 'earliest', **apache_kafka_ssl_config})\n",
    "consumer.subscribe([apache_kafka_input_topic_name])\n",
    "\n",
    "CLEANR = re.compile('<.*?>') \n",
    "\n",
    "def get_json_body(message):    \n",
    "    decoded_message = message.value().decode('utf-8') # Decode from binary \n",
    "    json_message = json.loads(decoded_message)  # Parse JSON message\n",
    "    return json_message\n",
    "\n",
    "def get_clean_content(json_object):    \n",
    "    content = json_object.get(\"content\", \"\")  # Retrieve 'content' property    \n",
    "    only_text = re.sub(CLEANR, '', content)\n",
    "    return only_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Apache Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = Producer({\n",
    "    'bootstrap.servers': apache_kafka_uri, \n",
    "    **apache_kafka_ssl_config \n",
    "})\n",
    "\n",
    "# Send a message to a Kafka topic\n",
    "def send_message(message, topic_name):\n",
    "    producer.produce(topic_name, json.dumps(message).encode('utf-8'))\n",
    "    producer.flush()\n",
    "    \n",
    "def send_enriched_data(message, offensive_score, is_offensive, sentiment_score, sentiment_label):\n",
    "    message['offensive_score'] = offensive_score\n",
    "    message['is_offensice'] = is_offensive\n",
    "    message['sentiment_score'] = sentiment_score\n",
    "    message['sentiment_label'] = sentiment_label\n",
    "    send_message(message, apache_kafka_enriched_output_topic_name)\n",
    "    \n",
    "def report_processing_error(message, error_code, error_message):\n",
    "    message['processing_error_code'] = error_code\n",
    "    message['processing_error_message'] = error_message\n",
    "    send_message(message, apache_kafka_processing_errors_topic_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read messages from Apache Kafka **input topic** and push processed data back to **output topic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing messages\")\n",
    "while True:\n",
    "    message = consumer.poll(1.0)  # Poll for messages, with a timeout of 1 second\n",
    "    if message is None:\n",
    "        continue\n",
    "\n",
    "    if message.error():\n",
    "        if message.error().code() == KafkaError._PARTITION_EOF:\n",
    "            # End of partition event\n",
    "            print(f\"Reached end of partition for topic {message.topic()} [{message.partition()}]\")\n",
    "        else:\n",
    "            print(f\"Error while consuming message: {message.error()}\")\n",
    "    else:\n",
    "        # Process the message\n",
    "        json_body = get_json_body(message)\n",
    "        content_property = get_clean_content(json_body)\n",
    "        if content_property == \"\":\n",
    "            continue\n",
    "        try:\n",
    "            # Get offensive probability\n",
    "            offensive_result = invoke_model_endpoint('twitter-roberta-base-offensive-endpoint', content_property)[0]\n",
    "            print(offensive_result)\n",
    "            offensive_score = offensive_result['score']\n",
    "            offensive_label = offensive_result['label']\n",
    "\n",
    "            # Get sentiment probability\n",
    "            sentiment_result = invoke_model_endpoint('roberta-base-sentiment', content_property)[0]\n",
    "            sentiment_score = sentiment_result['score']\n",
    "            sentiment_label = sentiment_result['label']\n",
    "            \n",
    "\n",
    "            print('Inference:')\n",
    "            print(f\"Input text: '{content_property}'\")\n",
    "            print(f\"Offensive score: {offensive_score}\")\n",
    "            print(f\"The message is: {offensive_label}\")\n",
    "            print(f\"Sentiment score: {sentiment_score}\")\n",
    "            print(f\"The message is: {sentiment_label}\")\n",
    "\n",
    "            send_enriched_data(json_body, offensive_result['score'], offensive_result['label'], sentiment_result['score'], sentiment_result['label'])\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            response = getattr(e, \"response\", {})\n",
    "            error_code = response.get(\"Error\", {}).get(\"Code\", \"Unknown\")\n",
    "            error_message = response.get(\"Error\", {}).get(\"Message\", \"Unknown\")\n",
    "            report_processing_error(json_body, error_code, error_message)\n",
    "            \n",
    "\n",
    "# Close the consumer\n",
    "consumer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
